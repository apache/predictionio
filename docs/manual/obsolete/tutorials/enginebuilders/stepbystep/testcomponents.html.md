---
title: Testing Engine Components
---

# Testing Engine Components

During development, you may want to run each component step by step to test out
the data pipeline. In this tutorial, we will demonstrate how to do it easily.

## Test Run DataSource

In `java-local-tutorial/src/main/java/recommendations/tutorial2`, you can find
`Runner1.java`. It is a small program that uses `JavaSimpleEngineBuilder` to
build an engine and uses `JavaWorkflow` to run the workflow.

To test the *DataSource* component, we can simply create an Engine with the
*DataSource* component only and leave other components empty:

```java
private static class HalfBakedEngineFactory implements IJavaEngineFactory {
  public JavaSimpleEngine<TrainingData, Object, Query, Float, Object> apply() {
    return new JavaSimpleEngineBuilder<
      TrainingData, Object, Query, Float, Object> ()
      .dataSourceClass(DataSource.class)
      .build();
  }
}
```
Similarly, we only need to add the `DataSourceParams` to
`JavaEngineParamsBuilder`.

```java
JavaEngineParams engineParams = new JavaEngineParamsBuilder()
  .dataSourceParams(new DataSourceParams(filePath))
  .build();
```

Then, you can run this Engine by using `JavaWorkflow`.

```java
    JavaWorkflow.runEngine(
      (new HalfBakedEngineFactory()).apply(),
      engineParams,
      null,
      new EmptyParams(),
      new WorkflowParamsBuilder().batch("MyEngine").verbose(3).build()
    );
```

For quick testing purpose, a very simple test data is provided in
`data/test/ratings.csv`. Each row of the file represents user ID, item ID, and
the rating value:

```
1,1,2
1,2,3
1,3,4
...
```

The `Runner1.java` takes the path of the rating file as argument. Execute the
following command to run (The `../../bin/pio run` command will automatically
compile and package the JARs):

```
$ cd $PIO_HOME/examples/java-local-tutorial
$ ../../bin/pio run org.apache.predictionio.examples.java.recommendations.tutorial2.Runner1 -- -- data/test/ratings.csv
```
where `$PIO_HOME` is the root directory of the PredictionIO code tree. The two
`--` are to separate parameters passed to `pio run` (the `Runner1` class in this
case`), parameters passed to Apache Spark (no special parameters in this case),
and parameters passed to the main class (the CSV file in this case).

If it runs successfully, you should see the following console output at the end.
It prints out the `TrainingData` generated by `DataSource`.

```
2014-09-30 16:00:01,321 INFO  spark.SparkContext - Job finished: collect at Workflow.scala:388, took 0.024613 s
2014-09-30 16:00:01,322 INFO  workflow.CoreWorkflow$ - Data Set 0
2014-09-30 16:00:01,323 INFO  workflow.CoreWorkflow$ - Params: null
2014-09-30 16:00:01,323 INFO  workflow.CoreWorkflow$ - TrainingData:
2014-09-30 16:00:01,323 INFO  workflow.CoreWorkflow$ - [[(1,1,2.0), (1,2,3.0), (1,3,4.0), (2,3,4.0), (2,4,1.0), (3,2,2.0), (3,3,1.0), (3,4,3.0), (4,1,5.0), (4,2,3.0), (4,4,2.0)]]
2014-09-30 16:00:01,324 INFO  workflow.CoreWorkflow$ - TestingData: (count=0)
2014-09-30 16:00:01,324 INFO  workflow.CoreWorkflow$ - Data source complete
2014-09-30 16:00:01,324 INFO  workflow.CoreWorkflow$ - Preparator is null. Stop here
```

As you can see, it stops after running the *DataSource* component and it prints
out *Training Data* for debugging.

## Test Run Algorithm

By simply adding `addAlgorithmClass()` and `addAlgorithmParams()` in the
`JavaSimpleEngineBuilder` and `JavaEngineParamsBuilder`, you can test the
`Algorithm` class in the workflow as well, as shown in `Runner2.java`:

```java
private static class HalfBakedEngineFactory implements IJavaEngineFactory {
  public JavaSimpleEngine<TrainingData, Object, Query, Float, Object> apply() {
    return new JavaSimpleEngineBuilder<
      TrainingData, Object, Query, Float, Object> ()
      .dataSourceClass(DataSource.class)
      .preparatorClass() // Use default Preparator
      .addAlgorithmClass("MyRecommendationAlgo", Algorithm.class) // Add Algorithm
      .build();
  }
}
```

```java
JavaEngineParams engineParams = new JavaEngineParamsBuilder()
  .dataSourceParams(new DataSourceParams(filePath))
  .addAlgorithmParams("MyRecommendationAlgo", new AlgoParams(0.2)) // Add Algorithm Params
  .build();
```

Execute the following command to run:

```
$ cd $PIO_HOME/examples/java-local-tutorial
$ ../../bin/pio run org.apache.predictionio.examples.java.recommendations.tutorial2.Runner2 -- -- data/test/ratings.csv
```

You should see the *Model* generated by the Algorithm at the end of the console
output:

```
2014-09-30 16:05:54,275 INFO  spark.SparkContext - Job finished: collect at WorkflowUtils.scala:179, took 0.037635 s
2014-09-30 16:05:54,276 INFO  workflow.CoreWorkflow$ - [Model: [itemSimilarity: {1=org.apache.commons.math3.linear.OpenMapRealVector@65fa6c0, 2=org.apache.commons.math3.linear.OpenMapRealVector@c2eb7f66, 3=org.apache.commons.math3.linear.OpenMapRealVector@2302395e, 4=org.apache.commons.math3.linear.OpenMapRealVector@d2fb7858}]
[userHistory: {1=org.apache.commons.math3.linear.OpenMapRealVector@5a1123a3, 2=org.apache.commons.math3.linear.OpenMapRealVector@d1225bfd, 3=org.apache.commons.math3.linear.OpenMapRealVector@572123a3, 4=org.apache.commons.math3.linear.OpenMapRealVector@a51523a3}]]
2014-09-30 16:05:54,276 INFO  workflow.CoreWorkflow$ - Serving is null. Stop here
```

By adding each component step by step, we can easily test and debug the data
pipeline.

Next: [Evaluation](evaluation.html)
